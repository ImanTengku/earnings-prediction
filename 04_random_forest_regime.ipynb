{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 — Random Forest + Regime Analysis\n",
    "\n",
    "**Goal:** Upgrade from Logistic Regression to LightGBM.\n",
    "\n",
    "Key additions:\n",
    "- Full feature set\n",
    "- Feature importance chart — does rate_regime show up as significant?\n",
    "- SHAP values — why is the model predicting what it predicts?\n",
    "- Regime interaction test — do different features matter in different rate environments?\n",
    "- 3-class target (Buy / Hold / Sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Imports ────────────────────────────────────────────────────\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, log_loss, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# ── Load dataset ───────────────────────────────────────────────\n",
    "panel = pd.read_csv('../data/panel_dataset.csv', parse_dates=['earn_date'])\n",
    "panel = panel.sort_values('earn_date').reset_index(drop=True)\n",
    "print(f'Loaded: {panel.shape[0]} events, {panel[\"ticker\"].nunique()} tickers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Feature set ────────────────────────────────────────────────\n",
    "EXCLUDE = [\n",
    "    'ticker', 'earn_date', 'sector',\n",
    "    'target_binary', 'target_mag',\n",
    "    'stock_ret_5d', 'spx_ret_5d', 'excess_ret_5d',\n",
    "    'sue_quintile', 'vol_high'\n",
    "]\n",
    "\n",
    "# Encode sector\n",
    "le = LabelEncoder()\n",
    "panel['sector_enc'] = le.fit_transform(panel['sector'].fillna('Unknown'))\n",
    "\n",
    "ALL_FEATURES = [\n",
    "    c for c in panel.columns\n",
    "    if c not in EXCLUDE and panel[c].dtype in ['float64', 'int64']\n",
    "]\n",
    "\n",
    "print(f'Total features: {len(ALL_FEATURES)}')\n",
    "print(ALL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Prepare X and y ────────────────────────────────────────────\n",
    "df_model = panel[\n",
    "    ALL_FEATURES + ['target_binary', 'target_mag',\n",
    "                    'earn_date', 'excess_ret_5d',\n",
    "                    'ticker', 'rate_regime']\n",
    "].copy()\n",
    "df_model = df_model.dropna(subset=['target_binary', 'sue']).reset_index(drop=True)\n",
    "\n",
    "X      = df_model[ALL_FEATURES].values\n",
    "y_bin  = df_model['target_binary'].values\n",
    "y_mag  = df_model['target_mag'].values\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "print(f'Dataset: {X.shape[0]} events x {X.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── LightGBM Binary Classification ────────────────────────────\n",
    "tscv = TimeSeriesSplit(n_splits=5, gap=5)\n",
    "\n",
    "lgbm_params = dict(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=25,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "fold_results = []\n",
    "all_proba    = np.zeros(len(y_bin))\n",
    "\n",
    "print('Training LightGBM with TimeSeriesSplit...\\n')\n",
    "print(f'  {\"Fold\":<6} {\"Accuracy\":<12} {\"AUC\":<10} {\"LogLoss\"}')\n",
    "print('  ' + '-'*40)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y_bin[train_idx], y_bin[test_idx]\n",
    "\n",
    "    model = lgb.LGBMClassifier(**lgbm_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_te, y_te)],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(40, verbose=False),\n",
    "            lgb.log_evaluation(-1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    proba = model.predict_proba(X_te)[:, 1]\n",
    "    all_proba[test_idx] = proba\n",
    "\n",
    "    acc = accuracy_score(y_te, (proba > 0.5).astype(int))\n",
    "    auc = roc_auc_score(y_te, proba)\n",
    "    ll  = log_loss(y_te, proba)\n",
    "\n",
    "    fold_results.append({'fold': fold+1, 'acc': acc, 'auc': auc, 'logloss': ll})\n",
    "    print(f'  {fold+1:<6} {acc:<12.3f} {auc:<10.3f} {ll:.3f}')\n",
    "\n",
    "res = pd.DataFrame(fold_results)\n",
    "print(f'\\n  Mean Accuracy : {res[\"acc\"].mean():.3f} +/- {res[\"acc\"].std():.3f}')\n",
    "print(f'  Mean AUC      : {res[\"auc\"].mean():.3f} +/- {res[\"auc\"].std():.3f}')\n",
    "\n",
    "df_model['lgbm_proba'] = all_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Feature Importance ─────────────────────────────────────────\n",
    "full_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "full_model.fit(X, y_bin, callbacks=[lgb.log_evaluation(-1)])\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature':    ALL_FEATURES,\n",
    "    'importance': full_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, max(6, len(ALL_FEATURES)*0.3)))\n",
    "top_n = importance_df.head(25)\n",
    "\n",
    "colors = []\n",
    "for feat in top_n['feature']:\n",
    "    if feat in ['rate_regime', 'vix_regime', 'tnx', 'vix', 'tnx_1m_chg', 'vix_5d_chg']:\n",
    "        colors.append('#F44336')   # macro = red\n",
    "    elif feat in ['sue', 'eps_surprise_pct', 'hist_beat_rate', 'beat_streak']:\n",
    "        colors.append('#4CAF50')   # earnings = green\n",
    "    elif 'ret_' in feat or 'rsi' in feat or 'ma' in feat:\n",
    "        colors.append('#2196F3')   # technical = blue\n",
    "    else:\n",
    "        colors.append('#9C27B0')   # other = purple\n",
    "\n",
    "ax.barh(top_n['feature'], top_n['importance'], color=colors, edgecolor='white')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Feature Importance (LightGBM Gain)')\n",
    "ax.set_title('Feature Importance\\nRed=Macro  Green=Earnings  Blue=Technical  Purple=Other')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/04_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "rate_rows = importance_df[importance_df['feature'] == 'rate_regime']\n",
    "if not rate_rows.empty:\n",
    "    rank = importance_df.index.get_loc(rate_rows.index[0]) + 1\n",
    "    print(f'rate_regime rank: #{rank} of {len(importance_df)}')\n",
    "    print('If in top 15, structural break theory is validated by the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── SHAP Analysis ──────────────────────────────────────────────\n",
    "print('Computing SHAP values (takes ~1 minute)...')\n",
    "explainer   = shap.TreeExplainer(full_model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "sv = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "shap.summary_plot(sv, X, feature_names=ALL_FEATURES,\n",
    "                  max_display=15, show=False, plot_type='bar')\n",
    "axes[0].set_title('Mean |SHAP| — Overall Importance')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "shap.summary_plot(sv, X, feature_names=ALL_FEATURES,\n",
    "                  max_display=15, show=False)\n",
    "axes[1].set_title('SHAP Beeswarm — Direction and Magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/04_shap_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('How to read the beeswarm:')\n",
    "print('  Right of 0 = increases P(outperform)')\n",
    "print('  Red dots = high feature value, Blue = low feature value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Regime Comparison ──────────────────────────────────────────\n",
    "low_rate_idx  = np.where(df_model['rate_regime'].values == 0)[0]\n",
    "high_rate_idx = np.where(df_model['rate_regime'].values == 1)[0]\n",
    "\n",
    "regime_importances = {}\n",
    "\n",
    "for name, idx in [('Low Rate (2019-21)', low_rate_idx),\n",
    "                   ('High Rate (2022+)',  high_rate_idx)]:\n",
    "    if len(idx) < 100:\n",
    "        print(f'Skipping {name}: only {len(idx)} samples')\n",
    "        continue\n",
    "    m = lgb.LGBMClassifier(**lgbm_params)\n",
    "    m.fit(X[idx], y_bin[idx], callbacks=[lgb.log_evaluation(-1)])\n",
    "    regime_importances[name] = pd.Series(\n",
    "        m.feature_importances_, index=ALL_FEATURES\n",
    "    ).sort_values(ascending=False)\n",
    "    print(f'{name}: {len(idx)} events')\n",
    "\n",
    "if len(regime_importances) == 2:\n",
    "    top_features = list(regime_importances.values())[0].head(15).index\n",
    "    comp = pd.DataFrame(regime_importances)[top_features].T\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11, 6))\n",
    "    x     = np.arange(len(top_features))\n",
    "    width = 0.38\n",
    "\n",
    "    ax.bar(x - width/2, comp.iloc[0], width,\n",
    "           label=comp.index[0], color='#2196F3', alpha=0.85, edgecolor='white')\n",
    "    ax.bar(x + width/2, comp.iloc[1], width,\n",
    "           label=comp.index[1], color='#F44336', alpha=0.85, edgecolor='white')\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_features, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_ylabel('Feature Importance')\n",
    "    ax.set_title('Feature Importance by Rate Regime (Testing Structural Break Theory)')\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/04_regime_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('If bars differ significantly between regimes, structural break is real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 3-Class Model: Buy / Hold / Sell ──────────────────────────\n",
    "print('Training 3-class magnitude model...')\n",
    "\n",
    "tscv3        = TimeSeriesSplit(n_splits=5, gap=5)\n",
    "all_pred_mag = np.full(len(y_mag), -1, dtype=int)\n",
    "fold_accs    = []\n",
    "\n",
    "for fold, (tr, te) in enumerate(tscv3.split(X)):\n",
    "    m = lgb.LGBMClassifier(\n",
    "        n_estimators=500, learning_rate=0.03, max_depth=5,\n",
    "        num_leaves=31, min_child_samples=25, subsample=0.8,\n",
    "        colsample_bytree=0.7, reg_alpha=0.1, reg_lambda=0.1,\n",
    "        random_state=42, verbose=-1,\n",
    "        objective='multiclass', num_class=3\n",
    "    )\n",
    "    m.fit(X[tr], y_mag[tr], callbacks=[lgb.log_evaluation(-1)])\n",
    "    preds = m.predict(X[te])\n",
    "    all_pred_mag[te] = preds\n",
    "    fold_accs.append(accuracy_score(y_mag[te], preds))\n",
    "\n",
    "print(f'3-Class Accuracy: {np.mean(fold_accs):.3f} +/- {np.std(fold_accs):.3f}')\n",
    "print(f'Naive baseline (always Neutral): {(y_mag == 1).mean():.3f}')\n",
    "\n",
    "valid_mask = all_pred_mag >= 0\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_mag[valid_mask], all_pred_mag[valid_mask],\n",
    "    display_labels=['Sig. Miss', 'Neutral', 'Sig. Beat'],\n",
    "    cmap='Blues', ax=ax\n",
    ")\n",
    "ax.set_title('3-Class Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/04_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "df_model['lgbm_pred_mag'] = all_pred_mag\n",
    "df_model[[\n",
    "    'ticker', 'earn_date', 'target_binary', 'target_mag',\n",
    "    'excess_ret_5d', 'lgbm_proba', 'lgbm_pred_mag',\n",
    "    'rate_regime', 'vix_regime'\n",
    "]].to_csv('../data/lgbm_predictions.csv', index=False)\n",
    "print('Predictions saved to data/lgbm_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
