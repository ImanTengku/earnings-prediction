{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — Data Collection & Panel Dataset\n",
    "\n",
    "**Goal:** Pull price data, earnings history, and macro regime data for the full S&P 500. \n",
    "Merge everything into one flat panel dataset where **each row = one earnings event**.\n",
    "\n",
    "**Data Sources:**\n",
    "- `yfinance` — Price/Volume, ^TNX (10Y Yield), ^VIX\n",
    "- `yfinance` earnings history — EPS Actual vs Estimate (proxy for Capital IQ)\n",
    "- *(If you have Capital IQ access, swap in true consensus dispersion for SUE)*\n",
    "\n",
    "**Output:** `data/panel_dataset.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # so we can import from utils/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils.helpers import (\n",
    "    get_sp500_tickers, get_price_data, get_spx_returns,\n",
    "    get_macro_data, get_earnings_history,\n",
    "    compute_technical_features, compute_ticker_history_features,\n",
    "    compute_targets, compute_magnitude_class\n",
    ")\n",
    "\n",
    "import os\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configuration ──────────────────────────────────────────────\n",
    "START_DATE     = '2019-01-01'\n",
    "END_DATE       = '2024-12-31'\n",
    "POST_DAYS      = 5       # hold period for return calculation\n",
    "PRE_WINDOW     = 30      # trading days of pre-earnings price history\n",
    "MIN_PRICE      = 5.0     # skip penny stocks\n",
    "MAX_TICKERS    = 100     # set to None for full S&P 500 (takes ~45 min)\n",
    "\n",
    "print(f'Date range : {START_DATE} → {END_DATE}')\n",
    "print(f'Post-earnings hold : {POST_DAYS} days')\n",
    "print(f'Tickers    : {\"All S&P 500\" if MAX_TICKERS is None else MAX_TICKERS} (for testing)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 1: Load macro data (rates + VIX) ─────────────────────\n",
    "print('Downloading macro data (^TNX, ^VIX)...')\n",
    "macro = get_macro_data(start=START_DATE, end=END_DATE)\n",
    "print(f'Macro data shape: {macro.shape}')\n",
    "macro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 2: Load S&P 500 returns for alpha calculation ─────────\n",
    "print('Downloading S&P 500 index returns...')\n",
    "spx = get_spx_returns(start=START_DATE, end=END_DATE)\n",
    "print(f'SPX data shape: {spx.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 3: Get ticker universe ────────────────────────────────\n",
    "print('Fetching S&P 500 tickers...')\n",
    "all_tickers, sector_map = get_sp500_tickers()\n",
    "tickers = all_tickers[:MAX_TICKERS] if MAX_TICKERS else all_tickers\n",
    "print(f'Tickers loaded: {len(tickers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 4: Main loop — build one row per earnings event ───────\n",
    "records = []\n",
    "skipped = []\n",
    "\n",
    "for ticker in tqdm(tickers, desc='Processing tickers'):\n",
    "    \n",
    "    # --- Price data ---\n",
    "    price = get_price_data(ticker, start=START_DATE, end=END_DATE)\n",
    "    if price is None or price['close'].iloc[-1] < MIN_PRICE:\n",
    "        skipped.append((ticker, 'no price data'))\n",
    "        continue\n",
    "\n",
    "    # --- Earnings history ---\n",
    "    earn = get_earnings_history(ticker)\n",
    "    if earn is None or len(earn) < 4:\n",
    "        skipped.append((ticker, 'insufficient earnings history'))\n",
    "        continue\n",
    "\n",
    "    # Filter to our date range\n",
    "    earn = earn[(earn.index >= START_DATE) & (earn.index <= END_DATE)]\n",
    "    if len(earn) < 2:\n",
    "        skipped.append((ticker, 'no earnings in date range'))\n",
    "        continue\n",
    "\n",
    "    # --- Per-event feature extraction ---\n",
    "    all_earn_dates = earn.index.tolist()\n",
    "\n",
    "    for earn_date in all_earn_dates:\n",
    "        try:\n",
    "            # Pre-earnings price window\n",
    "            pre = price[price.index < earn_date].tail(PRE_WINDOW)\n",
    "            if len(pre) < 20:\n",
    "                continue\n",
    "            prev_close = pre.iloc[-1]['close']\n",
    "\n",
    "            # Post-earnings return (stock)\n",
    "            post = price[price.index > earn_date]\n",
    "            if len(post) < POST_DAYS:\n",
    "                continue\n",
    "            post_close   = post.iloc[POST_DAYS - 1]['close']\n",
    "            stock_ret_5d = post_close / prev_close - 1\n",
    "\n",
    "            # Post-earnings return (S&P 500) — same window\n",
    "            spx_window = spx[\n",
    "                (spx.index > earn_date)\n",
    "            ].head(POST_DAYS)\n",
    "            if len(spx_window) < POST_DAYS:\n",
    "                continue\n",
    "            spx_ret_5d = (\n",
    "                spx_window.iloc[-1]['spx_close'] /\n",
    "                spx_window.iloc[0]['spx_close'] - 1\n",
    "            )\n",
    "\n",
    "            # Target variables\n",
    "            target_binary, excess_ret = compute_targets(stock_ret_5d, spx_ret_5d)\n",
    "            target_mag = compute_magnitude_class(excess_ret)\n",
    "\n",
    "            # Macro regime on earnings date\n",
    "            macro_on_date = macro[macro.index <= earn_date]\n",
    "            if macro_on_date.empty:\n",
    "                continue\n",
    "            macro_row = macro_on_date.iloc[-1]\n",
    "\n",
    "            # Technical features\n",
    "            tech = compute_technical_features(pre)\n",
    "\n",
    "            # Ticker historical earnings behavior\n",
    "            past_dates = [d for d in all_earn_dates if d < earn_date]\n",
    "            hist_feats = compute_ticker_history_features(price, past_dates)\n",
    "\n",
    "            # Earnings surprise row\n",
    "            earn_row = earn.loc[earn_date]\n",
    "\n",
    "            # Assemble record\n",
    "            row = {\n",
    "                # Identifiers\n",
    "                'ticker':         ticker,\n",
    "                'earn_date':      earn_date,\n",
    "                'sector':         sector_map.get(ticker, 'Unknown'),\n",
    "                'quarter':        earn_date.quarter,\n",
    "                'year':           earn_date.year,\n",
    "\n",
    "                # Targets\n",
    "                'target_binary':  target_binary,\n",
    "                'target_mag':     target_mag,\n",
    "                'stock_ret_5d':   stock_ret_5d,\n",
    "                'spx_ret_5d':     spx_ret_5d,\n",
    "                'excess_ret_5d':  excess_ret,\n",
    "\n",
    "                # Earnings surprise signals\n",
    "                'sue':              earn_row.get('sue', np.nan),\n",
    "                'eps_surprise_pct': earn_row.get('eps_surprise_pct', np.nan),\n",
    "                'hist_beat_rate':   earn_row.get('hist_beat_rate', np.nan),\n",
    "                'beat_streak':      earn_row.get('beat_streak', np.nan),\n",
    "\n",
    "                # Macro regime\n",
    "                'tnx':              macro_row['tnx'],\n",
    "                'vix':              macro_row['vix'],\n",
    "                'rate_regime':      macro_row['rate_regime'],\n",
    "                'vix_regime':       macro_row['vix_regime'],\n",
    "                'tnx_1m_chg':       macro_row['tnx_1m_chg'],\n",
    "                'vix_5d_chg':       macro_row['vix_5d_chg'],\n",
    "            }\n",
    "\n",
    "            # Add technical features\n",
    "            row.update(tech)\n",
    "            # Add historical behavior features\n",
    "            row.update(hist_feats)\n",
    "\n",
    "            records.append(row)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue  # skip malformed events silently\n",
    "\n",
    "print(f'\\nTotal events collected : {len(records)}')\n",
    "print(f'Tickers skipped        : {len(skipped)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 5: Build DataFrame and save ──────────────────────────\n",
    "panel = pd.DataFrame(records)\n",
    "panel = panel.sort_values('earn_date').reset_index(drop=True)\n",
    "\n",
    "print(f'Panel shape: {panel.shape}')\n",
    "print(f'Date range : {panel[\"earn_date\"].min()} → {panel[\"earn_date\"].max()}')\n",
    "print(f'Unique tickers: {panel[\"ticker\"].nunique()}')\n",
    "print(f'\\nClass balance (target_binary):')\n",
    "print(panel['target_binary'].value_counts(normalize=True).round(3))\n",
    "\n",
    "panel.to_csv('../data/panel_dataset.csv', index=False)\n",
    "print('\\n✓ Saved to data/panel_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 6: Data quality check ────────────────────────────────\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "fig.suptitle('Panel Dataset — Data Quality Overview', fontsize=14, y=1.02)\n",
    "\n",
    "# Events over time\n",
    "panel['earn_date'] = pd.to_datetime(panel['earn_date'])\n",
    "panel.groupby(panel['earn_date'].dt.to_period('Q')).size().plot(\n",
    "    ax=axes[0,0], title='Events per Quarter', kind='bar', color='steelblue'\n",
    ")\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Target balance\n",
    "panel['target_binary'].value_counts().plot(\n",
    "    ax=axes[0,1], title='Target Balance (0=Under, 1=Over)', kind='bar',\n",
    "    color=['tomato','steelblue']\n",
    ")\n",
    "\n",
    "# Excess return distribution\n",
    "axes[0,2].hist(panel['excess_ret_5d'].clip(-0.3, 0.3), bins=60, color='steelblue', edgecolor='white')\n",
    "axes[0,2].axvline(0, color='red', linestyle='--')\n",
    "axes[0,2].set_title('Excess Return Distribution (5d)')\n",
    "\n",
    "# Events per sector\n",
    "panel['sector'].value_counts().plot(\n",
    "    ax=axes[1,0], title='Events by Sector', kind='barh', color='steelblue'\n",
    ")\n",
    "\n",
    "# Rate regime over time\n",
    "rate_by_q = panel.groupby(panel['earn_date'].dt.to_period('Q'))['rate_regime'].mean()\n",
    "rate_by_q.plot(ax=axes[1,1], title='Rate Regime Over Time (1=High Rate)', color='darkorange')\n",
    "axes[1,1].axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Missing value heatmap\n",
    "missing = panel.isnull().mean().sort_values(ascending=False).head(15)\n",
    "missing.plot(ax=axes[1,2], title='Missing Value Rate (top 15 cols)', kind='barh', color='tomato')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/01_data_quality.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Plot saved to outputs/01_data_quality.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
