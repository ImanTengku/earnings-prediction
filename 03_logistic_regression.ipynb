{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 — Logistic Regression Baseline\n",
    "\n",
    "**Goal:** Prove the concept with a simple, interpretable model before moving to Random Forest.\n",
    "Logistic Regression gives us clean coefficients — we can see exactly what drives predictions.\n",
    "\n",
    "**Features used:**\n",
    "- `sue` — Standardized Unexpected Earnings\n",
    "- `ret_14d` — Pre-earnings 14-day momentum\n",
    "- `rate_regime` — High/Low rate environment\n",
    "- `vix_regime` — Fear/Complacency environment\n",
    "- `hist_beat_rate` — Historical beat frequency\n",
    "\n",
    "**Evaluation:** TimeSeriesSplit (never K-Fold), CAR plots on predicted winners/losers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Patched imports (run this first) ──────────────────────────\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, log_loss,\n",
    "    classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# ── Load dataset ───────────────────────────────────────────────\n",
    "panel = pd.read_csv('../data/panel_dataset.csv', parse_dates=['earn_date'])\n",
    "panel = panel.sort_values('earn_date').reset_index(drop=True)\n",
    "print(f'Loaded: {panel.shape[0]} events, {panel[\"ticker\"].nunique()} tickers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Feature selection ──────────────────────────────────────────\n",
    "LOGIT_FEATURES = [\n",
    "    'sue', 'eps_surprise_pct', 'hist_beat_rate', 'beat_streak',\n",
    "    'ret_5d', 'ret_14d', 'ret_20d',\n",
    "    'rvol_pctile', 'vol_term_ratio',\n",
    "    'vol_ratio_5d', 'vol_ratio_1d',\n",
    "    'rate_regime', 'vix_regime', 'tnx', 'vix', 'vix_5d_chg',\n",
    "    'ticker_avg_abs_move', 'ticker_up_rate',\n",
    "]\n",
    "\n",
    "# Keep only features that exist in the panel\n",
    "LOGIT_FEATURES = [f for f in LOGIT_FEATURES if f in panel.columns]\n",
    "print(f'Features available: {len(LOGIT_FEATURES)}')\n",
    "print(LOGIT_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Prepare X and y ────────────────────────────────────────────\n",
    "df_model = panel[LOGIT_FEATURES + ['target_binary', 'earn_date',\n",
    "                                    'excess_ret_5d', 'ticker']].copy()\n",
    "df_model = df_model.dropna(subset=['target_binary', 'sue'])\n",
    "df_model = df_model.sort_values('earn_date').reset_index(drop=True)\n",
    "\n",
    "X = df_model[LOGIT_FEATURES].values\n",
    "y = df_model['target_binary'].values\n",
    "\n",
    "print(f'Dataset: {X.shape[0]} events, {X.shape[1]} features')\n",
    "print(f'Class balance: {y.mean():.1%} outperform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── TimeSeriesSplit Cross-Validation ───────────────────────────\n",
    "# IMPORTANT: Always train on past, test on future.\n",
    "# Random K-Fold would leak future data — a critical error in finance.\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5, gap=5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('model',   LogisticRegression(\n",
    "        C=0.5,\n",
    "        class_weight='balanced',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "fold_results = []\n",
    "all_proba    = np.zeros(len(y))\n",
    "all_pred     = np.zeros(len(y))\n",
    "\n",
    "print('Running TimeSeriesSplit cross-validation...\\n')\n",
    "print(f'  {\"Fold\":<6} {\"Train N\":<10} {\"Test N\":<10} {\"Accuracy\":<12} {\"AUC\":<10} {\"LogLoss\"}')\n",
    "print('  ' + '-'*58)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    pred  = pipeline.predict(X_test)\n",
    "\n",
    "    all_proba[test_idx] = proba\n",
    "    all_pred[test_idx]  = pred\n",
    "\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    ll  = log_loss(y_test, proba)\n",
    "\n",
    "    fold_results.append({'fold': fold+1, 'train_n': len(train_idx),\n",
    "                         'test_n': len(test_idx), 'accuracy': acc,\n",
    "                         'auc': auc, 'logloss': ll})\n",
    "    print(f'  {fold+1:<6} {len(train_idx):<10} {len(test_idx):<10} '\n",
    "          f'{acc:<12.3f} {auc:<10.3f} {ll:.3f}')\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print('\\n  Averages:')\n",
    "print(f'  Accuracy : {results_df[\"accuracy\"].mean():.3f} +/- {results_df[\"accuracy\"].std():.3f}')\n",
    "print(f'  AUC      : {results_df[\"auc\"].mean():.3f} +/- {results_df[\"auc\"].std():.3f}')\n",
    "print(f'  LogLoss  : {results_df[\"logloss\"].mean():.3f} +/- {results_df[\"logloss\"].std():.3f}')\n",
    "print()\n",
    "print('Benchmark: Naive always-predict-outperform = 50.0% accuracy, AUC = 0.500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Calibration Curve ──────────────────────────────────────────\n",
    "test_mask = all_proba > 0\n",
    "prob_true, prob_pred = calibration_curve(\n",
    "    y[test_mask], all_proba[test_mask], n_bins=10\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "axes[0].plot(prob_pred, prob_true, 'o-', color='steelblue', linewidth=2, label='Model')\n",
    "axes[0].plot([0, 1], [0, 1], '--', color='gray', linewidth=1, label='Perfect calibration')\n",
    "axes[0].set_xlabel('Predicted Probability')\n",
    "axes[0].set_ylabel('Actual Fraction Positive')\n",
    "axes[0].set_title('Calibration Curve\\n(closer to diagonal = more reliable probabilities)')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(all_proba[test_mask & (y == 1)], bins=30, alpha=0.6,\n",
    "             color='green', label='Actual Outperform', density=True)\n",
    "axes[1].hist(all_proba[test_mask & (y == 0)], bins=30, alpha=0.6,\n",
    "             color='red', label='Actual Underperform', density=True)\n",
    "axes[1].axvline(0.5, color='black', linestyle='--')\n",
    "axes[1].set_xlabel('Predicted Probability of Outperform')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Predicted Probability Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/03_calibration.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Coefficient Plot ───────────────────────────────────────────\n",
    "pipeline.fit(X, y)\n",
    "coefs = pipeline.named_steps['model'].coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': LOGIT_FEATURES,\n",
    "    'coef':    coefs\n",
    "}).sort_values('coef', key=abs, ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, max(5, len(coef_df)*0.35)))\n",
    "colors = ['#2196F3' if c > 0 else '#F44336' for c in coef_df['coef']]\n",
    "ax.barh(coef_df['feature'], coef_df['coef'], color=colors, edgecolor='white')\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.set_xlabel('Coefficient Value')\n",
    "ax.set_title('Logistic Regression Coefficients\\n(Blue = increases P(outperform), Red = decreases)')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/03_coefficients.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Key check: Is SUE coefficient positive? (It should be)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Top-Decile Precision ───────────────────────────────────────\n",
    "df_model['proba']   = all_proba\n",
    "df_model['pred']    = all_pred\n",
    "df_model['in_test'] = (all_proba > 0).astype(int)\n",
    "\n",
    "df_test = df_model[df_model['in_test'] == 1].copy()\n",
    "df_test['confidence_decile'] = pd.qcut(\n",
    "    df_test['proba'].rank(method='first'), q=10, labels=False\n",
    ") + 1\n",
    "\n",
    "decile_stats = df_test.groupby('confidence_decile').agg(\n",
    "    actual_outperform_rate=('target_binary', 'mean'),\n",
    "    avg_excess_ret=('excess_ret_5d', 'mean'),\n",
    "    n_events=('target_binary', 'count')\n",
    ").reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "axes[0].bar(decile_stats['confidence_decile'],\n",
    "            decile_stats['actual_outperform_rate'] * 100,\n",
    "            color='steelblue', edgecolor='white')\n",
    "axes[0].axhline(50, color='red', linestyle='--', label='50% baseline')\n",
    "axes[0].set_xlabel('Confidence Decile (1=least, 10=most confident)')\n",
    "axes[0].set_ylabel('Actual Outperform Rate (%)')\n",
    "axes[0].set_title('Precision by Confidence Decile')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 100)\n",
    "\n",
    "axes[1].bar(decile_stats['confidence_decile'],\n",
    "            decile_stats['avg_excess_ret'] * 100,\n",
    "            color=['tomato' if v < 0 else 'steelblue'\n",
    "                   for v in decile_stats['avg_excess_ret']],\n",
    "            edgecolor='white')\n",
    "axes[1].axhline(0, color='black', linewidth=0.8)\n",
    "axes[1].set_xlabel('Confidence Decile')\n",
    "axes[1].set_ylabel('Avg Excess Return vs S&P 500 (%)')\n",
    "axes[1].set_title('Average Return by Confidence Decile')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/03_decile_precision.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "top = decile_stats[decile_stats['confidence_decile'] == 10].iloc[0]\n",
    "print(f'Top decile: {top[\"actual_outperform_rate\"]:.1%} outperform rate, '\n",
    "      f'{top[\"avg_excess_ret\"]*100:+.2f}% avg excess return')\n",
    "print('Target: >60% outperform rate in top decile for a tradeable signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Save predictions for backtest notebook ─────────────────────\n",
    "df_model[['ticker', 'earn_date', 'target_binary', 'excess_ret_5d',\n",
    "          'proba', 'pred']].to_csv(\n",
    "    '../data/logit_predictions.csv', index=False\n",
    ")\n",
    "print('Predictions saved to data/logit_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
